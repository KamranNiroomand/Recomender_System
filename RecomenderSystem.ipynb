{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMdSeX1ukTeZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Step 1: Preprocess the dataset\n",
        "df = pd.read_csv('answers.csv')  \n",
        "df = df[['j', 'qid', 'as']]  # Keep answerer user id, question id, answer score\n",
        "df = df.dropna()  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data preparation and evaluation for each question\n",
        "df['HitRate'] = 0  # Add a new column 'HitRate' initialized to 0\n",
        "similarity_threshold = 0.8  # Set the similarity threshold for considering recommendations\n",
        "\n",
        "total_hit_count = 0\n",
        "total_count = 0\n",
        "\n",
        "for question_id in df['qid'].unique():\n",
        "    question_df = df[df['qid'] == question_id]  # Filter dataframe for the current question\n",
        "    reader = Reader(rating_scale=(question_df['as'].min(), question_df['as'].max()))  # Define the rating scale for the current question\n",
        "    data = Dataset.load_from_df(question_df[['j', 'qid', 'as']], reader)  # Load the dataset for the current question\n",
        "    trainset = data.build_full_trainset()  # Build the full trainset for the current question\n",
        "\n",
        "    # Collaborative filtering (Matrix Factorization with SVD)\n",
        "    model = SVD()  # Use Singular Value Decomposition (SVD) algorithm\n",
        "    model.fit(trainset)\n",
        "\n",
        "    # Evaluation for the current question\n",
        "    testset_question = [(test_tuple[0], question_id, test_tuple[1]) for test_tuple in trainset.build_testset() if test_tuple[1] == question_id]\n",
        "    predictions = model.test(testset_question)\n",
        "\n",
        "    hit_count = 0\n",
        "    count = 0\n",
        "    for test_tuple, prediction in zip(testset_question, predictions):\n",
        "        user_id = test_tuple[0]\n",
        "        actual_answerer = test_tuple[2]\n",
        "        predicted_answerer = int(prediction.uid)\n",
        "\n",
        "        if actual_answerer == predicted_answerer or model.predict(user_id, actual_answerer).est >= similarity_threshold:\n",
        "            hit_count += 1\n",
        "        count += 1\n",
        "\n",
        "    hit_rate = hit_count / count if count > 0 else 0  # Calculate hit rate, handle division by zero\n",
        "    df.loc[df['qid'] == question_id, 'HitRate'] = hit_rate  # Update the 'HitRate' column for the specific question\n",
        "\n",
        "    total_hit_count += hit_count\n",
        "    total_count += count\n",
        "\n",
        "overall_hit_rate = total_hit_count / total_count if total_count > 0 else 0\n",
        "print(\"Overall Hit Rate:\", overall_hit_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCBWyyKXW2yd",
        "outputId": "90d0e6d6-5484-42d8-c898-326c6a13d7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Hit Rate: 0.6513933181473045\n"
          ]
        }
      ]
    }
  ]
}